{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Differential Operators New\n\nFor geophysical problems, the relationship between two physical quantities may include one of several differential operators:\n\n    - **Divergence:** $\\nabla \\cdot \\vec{u} = \\dfrac{\\partial u_x}{\\partial x} + \\dfrac{\\partial u_y}{\\partial y} + \\dfrac{\\partial u_y}{\\partial y}$\n    - **Gradient:** $\\nabla \\phi = \\dfrac{\\partial \\phi}{\\partial x}\\hat{x} + \\dfrac{\\partial \\phi}{\\partial y}\\hat{y} + \\dfrac{\\partial \\phi}{\\partial z}\\hat{z}$\n    - **Curl:** $\\nabla \\times \\vec{u} = \\Bigg ( \\dfrac{\\partial u_y}{\\partial z} - \\dfrac{\\partial u_z}{\\partial y} \\Bigg )\\hat{x} - \\Bigg ( \\dfrac{\\partial u_x}{\\partial z} - \\dfrac{\\partial u_z}{\\partial x} \\Bigg )\\hat{y} + \\Bigg ( \\dfrac{\\partial u_x}{\\partial y} - \\dfrac{\\partial u_y}{\\partial x} \\Bigg )\\hat{z}$\n\nWhen implementing the finite volume method, continuous variables are discretized to live at the cell centers, nodes, edges or faces of a mesh.\nThus for each differential operator, we need a discrete approximation that acts on the discrete variables living on the mesh.\nFor discretized quantities living on a mesh, sparse matricies can be used to approximate the differential operators according to\n:cite:`haber2014,HymanShashkov1999`.\n\n\n\nNumerical differential operators exist for 1D, 2D and 3D meshes. For each mesh\nclass (*Tensor mesh*, *Tree mesh*, *Curvilinear mesh*), the set of numerical\ndifferential operators are properties that are only constructed when called.\n\nHere we demonstrate:\n\n    - How to construct and apply numerical differential operators\n    - Mapping and dimensions\n    - Applications for the transpose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Packages\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from discretize import TensorMesh, TreeMesh\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# sphinx_gallery_thumbnail_number = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Numerical Differentiation in 1D\n\nDiscrete approximations for differential operators are derived using the principles\nof numerical differentiation. In 1D, so long as a function $f(x)$ is sufficiently smooth\nwithin the interval $[x-h/2, \\; x+h/2]$, the derivative of the function at $x$ is\napproximated by:\n\n\\begin{align}\\frac{df(x)}{dx} \\approx \\frac{f(x+h/2) \\; - \\; f(x-h/2)}{h}\\end{align}\n\nwhere the approximation becomes increasingly accurate as $h \\rightarrow 0$.\nThis principle can be applied to construct differential operators in 2D and 3D.\n\n.. figure:: ../../images/approximate_derivative.png\n    :align: center\n    :width: 300\n\n    Approximating the derivative of $f(x)$ using numerical differentiation.\n\n\nBelow we compute a scalar function on cell nodes and differentiate with\nrespect to x using a 1D differential operator. We then compute the analytic\nderivative of function to validate the numerical differentiation.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h], \"C\")\n\n# Get node and cell center locations\nx_nodes = mesh.vectorNx\nx_centers = mesh.vectorCCx\n\n# Compute function on nodes and derivative at cell centers\nv = np.exp(-(x_nodes ** 2) / 4 ** 2)\ndvdx = -(2 * x_centers / 4 ** 2) * np.exp(-(x_centers ** 2) / 4 ** 2)\n\n# Derivative in x (gradient in 1D) from nodes to cell centers\nG = mesh.nodalGrad\ndvdx_approx = G * v\n\n# Compare\nfig = plt.figure(figsize=(12, 4))\nax1 = fig.add_axes([0.05, 0.01, 0.3, 0.85])\nax1.spy(G, markersize=5)\nax1.set_title(\"Sparse representation of G\", pad=10)\n\nax2 = fig.add_axes([0.4, 0.06, 0.55, 0.85])\nax2.plot(x_nodes, v, \"b-\", x_centers, dvdx, \"r-\", x_centers, dvdx_approx, \"ko\")\nax2.set_title(\"Comparison plot\")\nax2.legend((\"function\", \"analytic derivative\", \"numeric derivative\"))\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Divergence\n\nLet us define a continuous scalar function $\\phi$ and a continuous\nvector function $\\vec{u}$ such that:\n\n\\begin{align}\\phi = \\nabla \\cdot \\vec{u}\\end{align}\n\nAnd let $\\boldsymbol{\\phi}$ and $\\boldsymbol{u}$ be the\ndiscrete representations of $\\phi$ and $\\vec{u}$\nthat live on the mesh (centers, nodes, edges or faces), respectively.\nProvided we know the discrete values $\\boldsymbol{u}$,\nour goal is to use discrete differentiation to approximate the values of\n$\\boldsymbol{\\phi}$.\nWe begin by considering a single cell (2D or 3D). We let the indices\n$i$, $j$ and $k$ \ndenote positions along the x, y and z axes, respectively.\n\n.. figure:: ../../images/divergence_discretization.png\n    :align: center\n    :width: 600\n\n    Discretization for approximating the divergence at the center of a single 2D cell (left) and 3D cell (right).\n\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n|             |                    **2D**                       |                       **3D**                        |\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n| **center**  | $(i,j)$                                   | $(i,j,k)$                                     |\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n| **x-faces** | $(i-\\frac{1}{2},j)\\;\\; (i+\\frac{1}{2},j)$ | $(i-\\frac{1}{2},j,k)\\;\\; (i+\\frac{1}{2},j,k)$ |\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n| **y-faces** | $(i,j-\\frac{1}{2})\\;\\; (i,j+\\frac{1}{2})$ | $(i,j-\\frac{1}{2},k)\\;\\; (i,j+\\frac{1}{2},k)$ |\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n| **z-faces** | N/A                                             | $(i,j,k-\\frac{1}{2})\\;\\; (i,j,k+\\frac{1}{2})$ |\n+-------------+-------------------------------------------------+-----------------------------------------------------+\n\nAs we will see, it makes the most sense for $\\boldsymbol{\\phi}$ to\nlive at the cell centers and\nfor the components of $\\boldsymbol{u}$ to live on the faces.\nIf $u_x$ lives on x-faces, then its discrete\nderivative with respect to $x$ lives at the cell center.\nAnd if $u_y$ lives on y-faces its discrete\nderivative with respect to $y$ lives at the cell center.\nLikewise for $u_z$. Thus to approximate the\ndivergence of $\\vec{u}$ at the cell center, we simply need to\nsum the discrete derivatives of $u_x$, $u_y$\nand $u_z$ that are defined at the cell center. Where $h_x$,\n$h_y$ and $h_z$ represent the dimension of the cell along the x, y and\nz directions, respectively:\n\n\\begin{align}\\begin{align}\n    \\mathbf{In \\; 2D:} \\;\\; \\phi(i,j) \\approx \\; & \\frac{u_x(i,j+\\frac{1}{2}) - u_x(i,j-\\frac{1}{2})}{h_x} \\\\\n    & + \\frac{u_y(i+\\frac{1}{2},j) - u_y(i-\\frac{1}{2},j)}{h_y}\n    \\end{align}\\end{align}\n\n|\n\n\\begin{align}\\begin{align}\n    \\mathbf{In \\; 3D:} \\;\\; \\phi(i,j,k) \\approx \\; & \\frac{u_x(i+\\frac{1}{2},j,k) - u_x(i-\\frac{1}{2},j,k)}{h_x} \\\\\n    & + \\frac{u_y(i,j+\\frac{1}{2},k) - u_y(i,j-\\frac{1}{2},k)}{h_y} \\\\\n    & + \\frac{u_z(i,j,k+\\frac{1}{2}) - u_z(i,j,k-\\frac{1}{2})}{h_z}\n    \\end{align}\\end{align}\n\n\nUltimately we are trying to approximate the divergence at the center of\nevery cell in a mesh. Adjacent cells share faces.\nIf the components $u_x$, $u_y$ and $u_z$ are\ncontinuous across their respective faces, then $\\boldsymbol{\\phi}$\nand $\\boldsymbol{u}$ can be related by a sparse matrix-vector product:\n\n\\begin{align}\\boldsymbol{\\phi} = \\boldsymbol{D \\, u}\\end{align}\n\nwhere $\\boldsymbol{D}$ is the divergence matrix from faces to cell centers,\n$\\boldsymbol{\\phi}$ is a vector containing the discrete approximations\nof $\\phi$ at all cell centers, and $\\boldsymbol{u}$ stores\nthe components of $\\vec{u}$ on cell faces as a vector of the form:\n\n\\begin{align}\\boldsymbol{u} = \\begin{bmatrix} \\boldsymbol{u_x} \\\\ \\boldsymbol{u_y} \\\\ \\boldsymbol{u_z} \\end{bmatrix}\\end{align}\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Divergence: Mapping and Dimensions\n\nWhen discretizing and solving differential equations, it is\nnatural for certain quantities to be defined at particular locations on the\nmesh; e.g.:\n\n   - Scalar quantities on nodes or at cell centers\n   - Vector quantities on cell edges or on cell faces\n\nAs such, numerical differential operators frequently map from one part of\nthe mesh to another. For example, the gradient acts on a scalar quantity\nan results in a vector quantity. As a result, the numerical gradient\noperator may map from nodes to edges or from cell centers to faces.\n\nHere we explore the dimensions of the divergence\noperator for a 3D tensor mesh. This can be extended to other mesh types.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h, h], \"CCC\")\n\n# Get differential operator\nDIV = mesh.faceDiv  # Divergence from faces to cell centers\n\n# Spy Plot\nfig = plt.figure(figsize=(6, 3))\nax1 = fig.add_axes([0.1, 0.05, 0.8, 0.8])\nax1.spy(DIV, markersize=0.5)\nax1.set_title(\"Divergence (faces to centers)\", pad=20)\nfig.show()\n\n# Print some properties\nprint(\"Divergence:\")\nprint(\"- Number of faces:\", str(mesh.nF))\nprint(\"- Number of cells:\", str(mesh.nC))\nprint(\"- Dimensions of operator:\", str(mesh.nC), \"x\", str(mesh.nF))\nprint(\"- Number of non-zero elements:\", str(DIV.nnz), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2D Divergence Example\n\nHere we apply the divergence operator to a function\ndefined on a 2D tensor mesh. We then plot the results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h], \"CC\")\n\n# Get differential operator\nDIV = mesh.faceDiv  # Divergence from faces to cell centers\n\n# Evaluate divergence of a vector function in x and y\nfaces_x = mesh.gridFx\nfaces_y = mesh.gridFy\n\nvx = (faces_x[:, 0] / np.sqrt(np.sum(faces_x ** 2, axis=1))) * np.exp(\n    -(faces_x[:, 0] ** 2 + faces_x[:, 1] ** 2) / 6 ** 2\n)\n\nvy = (faces_y[:, 1] / np.sqrt(np.sum(faces_y ** 2, axis=1))) * np.exp(\n    -(faces_y[:, 0] ** 2 + faces_y[:, 1] ** 2) / 6 ** 2\n)\n\nv = np.r_[vx, vy]\ndiv_v = DIV * v\n\n# Plot divergence of v\nfig = plt.figure(figsize=(10, 4.5))\n\nax1 = fig.add_subplot(121)\nmesh.plotImage(\n    v, ax=ax1, v_type=\"F\", view=\"vec\", stream_opts={\"color\": \"w\", \"density\": 1.0}\n)\nax1.set_title(\"v at cell faces\")\n\nax2 = fig.add_subplot(122)\nmesh.plotImage(div_v, ax=ax2)\nax2.set_title(\"divergence of v at cell centers\")\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tree Mesh Divergence Example\n\nFor a tree mesh, there needs to be special attention taken for the hanging\nfaces to achieve second order convergence for the divergence operator.\nAlthough the divergence cannot be constructed through Kronecker product\noperations, the initial steps are exactly the same for calculating the\nstencil, volumes, and areas. This yields a divergence defined for every\ncell in the mesh using all faces. There is, however, redundant information\nwhen hanging faces are included.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mesh = TreeMesh([[(1, 16)], [(1, 16)]], levels=4)\nmesh.insert_cells(np.array([5.0, 5.0]), np.array([3]))\nmesh.number()\n\nfig = plt.figure(figsize=(10, 10))\n\nax1 = fig.add_subplot(211)\n\nmesh.plotGrid(centers=True, nodes=False, ax=ax1)\nax1.axis(\"off\")\nax1.set_title(\"Simple QuadTree Mesh\")\nax1.set_xlim([-1, 17])\nax1.set_ylim([-1, 17])\n\nfor ii, loc in zip(range(mesh.nC), mesh.gridCC):\n    ax1.text(loc[0] + 0.2, loc[1], \"{0:d}\".format(ii), color=\"r\")\n\nax1.plot(mesh.gridFx[:, 0], mesh.gridFx[:, 1], \"g>\")\nfor ii, loc in zip(range(mesh.nFx), mesh.gridFx):\n    ax1.text(loc[0] + 0.2, loc[1], \"{0:d}\".format(ii), color=\"g\")\n\nax1.plot(mesh.gridFy[:, 0], mesh.gridFy[:, 1], \"m^\")\nfor ii, loc in zip(range(mesh.nFy), mesh.gridFy):\n    ax1.text(loc[0] + 0.2, loc[1] + 0.2, \"{0:d}\".format((ii + mesh.nFx)), color=\"m\")\n\nax2 = fig.add_subplot(212)\nax2.spy(mesh.faceDiv)\nax2.set_title(\"Face Divergence\")\nax2.set_ylabel(\"Cell Number\")\nax2.set_xlabel(\"Face Number\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient\n\nLet us define a continuous scalar function $\\phi$ and a continuous\nvector function $\\vec{u}$ such that:\n\n\\begin{align}\\vec{u} = \\nabla \\phi\\end{align}\n\nAnd let $\\boldsymbol{\\phi}$ and $\\boldsymbol{u}$ be the\ndiscrete representations of $\\phi$ and $\\vec{u}$\nthat live on the mesh (centers, nodes, edges or faces), respectively.\nProvided we know the discrete values $\\boldsymbol{\\phi}$,\nour goal is to use discrete differentiation to approximate the vector\ncomponents of $\\boldsymbol{u}$.\nWe begin by considering a single cell (2D or 3D). We let the indices\n$i$, $j$ and $k$ \ndenote positions along the x, y and z axes, respectively.\n\n.. figure:: ../../images/gradient_discretization.png\n    :align: center\n    :width: 600\n\n    Discretization for approximating the gradient on the edges of a single 2D cell (left) and 3D cell (right).\n\nAs we will see, it makes the most sense for $\\boldsymbol{\\phi}$\nto live at the cell nodes and for the components of\n$\\boldsymbol{u}$ to live on corresponding edges. If $\\phi$ lives on the nodes, then:\n\n    - the partial derivative $\\dfrac{\\partial \\phi}{\\partial x}\\hat{x}$ lives on x-edges,\n    - the partial derivative $\\dfrac{\\partial \\phi}{\\partial y}\\hat{y}$ lives on y-edges, and\n    - the partial derivative $\\dfrac{\\partial \\phi}{\\partial z}\\hat{z}$ lives on z-edges\n\nThus to approximate the gradient of $\\phi$, \nwe simply need to take discrete derivatives of $\\phi$ with respect\nto $x$, $y$ and $z$,\nand organize the resulting vector components on the corresponding edges.\nLet $h_x$, $h_y$ and $h_z$ represent the dimension of\nthe cell along the x, y and z directions, respectively.\n\n**In 2D**, the value of $\\phi$ at 4 node locations is used to\napproximate the vector components of the\ngradient at 4 edges locations (2 x-edges and 2 y-edges) as follows:\n\n\\begin{align}\\begin{align}\n    u_x \\Big ( i+\\frac{1}{2},j \\Big ) \\approx \\; & \\frac{\\phi (i+1,j) - \\phi (i,j)}{h_x} \\\\\n    u_x \\Big ( i+\\frac{1}{2},j+1 \\Big ) \\approx \\; & \\frac{\\phi (i+1,j+1) - \\phi (i,j+1)}{h_x} \\\\\n    u_y \\Big ( i,j+\\frac{1}{2} \\Big ) \\approx \\; & \\frac{\\phi (i,j+1) - \\phi (i,j)}{h_y} \\\\\n    u_y \\Big ( i+1,j+\\frac{1}{2} \\Big ) \\approx \\; & \\frac{\\phi (i+1,j+1) - \\phi (i+1,j)}{h_y}\n    \\end{align}\\end{align}\n\n**In 3D**, the value of $\\phi$ at 8 node locations is used to\napproximate the vector components of the\ngradient at 12 edges locations (4 x-edges, 4 y-edges and 4 z-edges).\nAn example of the approximation for each vector component is given below:\n\n\\begin{align}\\begin{align}\n    u_x \\Big ( i+\\frac{1}{2},j,k \\Big ) \\approx \\; & \\frac{\\phi (i+1,j,k) - \\phi (i,j,k)}{h_x} \\\\\n    u_y \\Big ( i,j+\\frac{1}{2},k \\Big ) \\approx \\; & \\frac{\\phi (i,j+1,k) - \\phi (i,j,k)}{h_y} \\\\\n    u_z \\Big ( i,j,k+\\frac{1}{2} \\Big ) \\approx \\; & \\frac{\\phi (i,j,k+1) - \\phi (i,j,k)}{h_z}\n    \\end{align}\\end{align}\n\n\nUltimately we are trying to approximate the vector components of the\ngradient at all edges of a mesh.\nAdjacent cells share nodes. If $\\phi$ is continuous at the nodes,\nthen $\\boldsymbol{\\phi}$ and $\\boldsymbol{u}$\ncan be related by a sparse matrix-vector product:\n\n\\begin{align}\\boldsymbol{u} = \\boldsymbol{G \\, \\phi}\\end{align}\n\nwhere $\\boldsymbol{G}$ is the gradient matrix that maps from\nnodes to edges, $\\boldsymbol{\\phi}$ is a vector containing\n$\\phi$ at all nodes,  and $\\boldsymbol{u}$ stores the\ncomponents of $\\vec{u}$ on cell edges as a vector of the form:\n\n\\begin{align}\\boldsymbol{u} = \\begin{bmatrix} \\boldsymbol{u_x} \\\\ \\boldsymbol{u_y} \\\\ \\boldsymbol{u_z} \\end{bmatrix}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gradient: Mapping and Dimensions\n\nHere we explore the dimensions of the gradient operator for a 3D tensor mesh.\nThis can be extended to other mesh types.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h, h], \"CCC\")\n\n# Get differential operators\nGRAD = mesh.nodalGrad  # Gradient from nodes to edges\n\n# Spy Plot\nfig = plt.figure(figsize=(3, 6))\nax1 = fig.add_axes([0.15, 0.05, 0.75, 0.8])\nax1.spy(GRAD, markersize=0.5)\nax1.set_title(\"Gradient (nodes to edges)\")\nfig.show()\n\n# Print some properties\nprint(\"\\n Gradient:\")\nprint(\"- Number of nodes:\", str(mesh.nN))\nprint(\"- Number of edges:\", str(mesh.nE))\nprint(\"- Dimensions of operator:\", str(mesh.nE), \"x\", str(mesh.nN))\nprint(\"- Number of non-zero elements:\", str(GRAD.nnz), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2D Gradient Example\n\nHere we apply the gradient operator to a\nfunction defined on a 2D tensor mesh. We then plot the results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h], \"CC\")\n\n# Get differential operators\nGRAD = mesh.nodalGrad  # Gradient from nodes to edges\n\n# Evaluate gradient of a scalar function\nnodes = mesh.gridN\nu = np.exp(-(nodes[:, 0] ** 2 + nodes[:, 1] ** 2) / 4 ** 2)\ngrad_u = GRAD * u\n\n# Plot Gradient of u\nfig = plt.figure(figsize=(10, 4.5))\n\nax1 = fig.add_subplot(121)\nmesh.plotImage(u, ax=ax1, v_type=\"N\")\nax1.set_title(\"u at cell centers\")\n\nax2 = fig.add_subplot(122)\nmesh.plotImage(\n    grad_u, ax=ax2, v_type=\"E\", view=\"vec\", stream_opts={\"color\": \"w\", \"density\": 1.0}\n)\nax2.set_title(\"gradient of u on edges\")\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Curl\n\nLet us define two continuous vector functions $\\vec{u}$ and\n$\\vec{w}$ such that:\n\n\\begin{align}\\vec{w} = \\nabla \\times \\vec{u}\\end{align}\n\nAnd let $\\boldsymbol{u}$ and $\\boldsymbol{w}$ be the\ndiscrete representations of $\\vec{u}$ and $\\vec{w}$\nthat live on the mesh (centers, nodes, edges or faces), respectively.\nProvided we know the discrete values $\\boldsymbol{u}$,\nour goal is to use discrete differentiation to approximate the vector\ncomponents of $\\boldsymbol{w}$.\nWe begin by considering a single 3D cell. We let the indices $i$,\n$j$ and $k$ denote positions along the x, y and z axes, respectively.\n\n.. figure:: ../../images/curl_discretization.png\n    :align: center\n    :width: 800\n\n    Discretization for approximating the x, y and z components of the curl on the respective faces of a 3D cell.\n\n\nAs we will see, it makes the most sense for the vector components of\n$\\boldsymbol{u}$ to live on the edges\nfor the vector components of $\\boldsymbol{w}$ to live the faces.\nIn this case, we need to approximate:\n\n\n    - the partial derivatives $\\dfrac{\\partial u_y}{\\partial z}$ and $\\dfrac{\\partial u_z}{\\partial y}$ to compute $w_x$,\n    - the partial derivatives $\\dfrac{\\partial u_x}{\\partial z}$ and $\\dfrac{\\partial u_z}{\\partial x}$ to compute $w_y$, and\n    - the partial derivatives $\\dfrac{\\partial u_x}{\\partial y}$ and $\\dfrac{\\partial u_y}{\\partial x}$ to compute $w_z$\n\n**In 3D**, discrete values at 12 edge locations (4 x-edges, 4 y-edges and 4 z-edges) are used to\napproximate the vector components of the curl at 6 face locations (2 x-faces, 2-faces and 2 z-faces).\nAn example of the approximation for each vector component is given below:\n\n\\begin{align}\\begin{align}\n    w_x \\Big ( i,j \\! +\\!\\!\\frac{1}{2},k \\! +\\!\\!\\frac{1}{2} \\Big ) \\!\\approx\\! \\; &\n    \\!\\Bigg ( \\! \\frac{u_z (i,j \\! +\\!\\!1,k \\! +\\!\\!\\frac{1}{2})  \\! -\\! u_z (i,j,k \\! +\\!\\!\\frac{1}{2})}{h_y} \\Bigg) \\!\n    \\! -\\! \\!\\Bigg ( \\! \\frac{u_y (i,j \\! +\\!\\!\\frac{1}{2},k \\! +\\!\\!1)  \\! -\\! u_y (i,j \\! +\\!\\!\\frac{1}{2},k)}{h_z} \\Bigg) \\! \\\\\n    & \\\\\n    w_y \\Big ( i \\! +\\!\\!\\frac{1}{2},j,k \\! +\\!\\!\\frac{1}{2} \\Big ) \\!\\approx\\! \\; &\n    \\!\\Bigg ( \\! \\frac{u_x (i \\! +\\!\\!\\frac{1}{2},j,k \\! +\\!\\!1)  \\! -\\! u_x (i \\! +\\!\\!\\frac{1}{2},j,k)}{h_z} \\Bigg)\n    \\! -\\! \\!\\Bigg ( \\! \\frac{u_z (i \\! +\\!\\!1,j,k \\! +\\!\\!\\frac{1}{2})  \\! -\\! u_z (i,j,k \\! +\\!\\!\\frac{1}{2})}{h_x} \\Bigg) \\! \\\\\n    & \\\\\n    w_z \\Big ( i \\! +\\!\\!\\frac{1}{2},j \\! +\\!\\!\\frac{1}{2},k \\Big ) \\!\\approx\\! \\; &\n    \\!\\Bigg ( \\! \\frac{u_y (i \\! +\\!\\!1,j \\! +\\!\\!\\frac{1}{2},k)  \\! -\\! u_y (i,j \\! +\\!\\!\\frac{1}{2},k)}{h_x} \\Bigg )\n    \\! -\\! \\!\\Bigg ( \\! \\frac{u_x (i \\! +\\!\\!\\frac{1}{2},j \\! +\\!\\!1,k)  \\! -\\! u_x (i \\! +\\!\\!\\frac{1}{2},j,k)}{h_y} \\Bigg) \\!\n    \\end{align}\\end{align}\n\n\nUltimately we are trying to approximate the curl on all the faces within a mesh.\nAdjacent cells share edges. If the components $u_x$, $u_y$ and $u_z$ are\ncontinuous across at the edges, then $\\boldsymbol{u}$ and $\\boldsymbol{w}$\ncan be related by a sparse matrix-vector product:\n\n\\begin{align}\\boldsymbol{w} = \\boldsymbol{C \\, u}\\end{align}\n\nwhere $\\boldsymbol{C}$ is the curl matrix from edges to faces,\n$\\boldsymbol{u}$ is a vector that stores the components of $\\vec{u}$ on cell edges,\nand $\\boldsymbol{w}$ is a vector that stores the components of\n$\\vec{w}$ on cell faces such that:\n\n\\begin{align}\\boldsymbol{u} = \\begin{bmatrix} \\boldsymbol{u_x} \\\\ \\boldsymbol{u_y} \\\\ \\boldsymbol{u_z} \\end{bmatrix}\n    \\;\\;\\;\\; \\textrm{and} \\;\\;\\;\\; \\begin{bmatrix} \\boldsymbol{w_x} \\\\ \\boldsymbol{w_y} \\\\ \\boldsymbol{w_z} \\end{bmatrix}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Curl: Mapping and Dimensions\n\nHere we explore the dimensions of the curl\noperator for a 3D tensor mesh. This can be extended to other mesh types.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h, h], \"CCC\")\n\n# Get differential operators\nCURL = mesh.edgeCurl  # Curl edges to cell centers\n\n# Spy Plot\nfig = plt.figure(figsize=(4, 4))\nax1 = fig.add_axes([0.1, 0.05, 0.8, 0.8])\nax1.spy(CURL, markersize=0.5)\nax1.set_title(\"Curl (edges to faces)\")\n\nfig.show()\n\n# Print some properties\nprint(\"Curl:\")\nprint(\"- Number of faces:\", str(mesh.nF))\nprint(\"- Number of edges:\", str(mesh.nE))\nprint(\"- Dimensions of operator:\", str(mesh.nE), \"x\", str(mesh.nF))\nprint(\"- Number of non-zero elements:\", str(CURL.nnz))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2D Curl Example\n\nHere we apply the curl operator to a\nfunction defined on a 2D tensor mesh. We then plot the results.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a uniform grid\nh = np.ones(20)\nmesh = TensorMesh([h, h], \"CC\")\n\n# Get differential operator\nCURL = mesh.edgeCurl  # Curl edges to cell centers (goes to faces in 3D)\n\n# Evaluate curl of a vector function in x and y\nedges_x = mesh.gridEx\nedges_y = mesh.gridEy\n\nwx = (-edges_x[:, 1] / np.sqrt(np.sum(edges_x ** 2, axis=1))) * np.exp(\n    -(edges_x[:, 0] ** 2 + edges_x[:, 1] ** 2) / 6 ** 2\n)\n\nwy = (edges_y[:, 0] / np.sqrt(np.sum(edges_y ** 2, axis=1))) * np.exp(\n    -(edges_y[:, 0] ** 2 + edges_y[:, 1] ** 2) / 6 ** 2\n)\n\nw = np.r_[wx, wy]\ncurl_w = CURL * w\n\n# Plot curl of w\nfig = plt.figure(figsize=(10, 4.5))\n\nax1 = fig.add_subplot(121)\nmesh.plotImage(\n    w, ax=ax1, v_type=\"E\", view=\"vec\", stream_opts={\"color\": \"w\", \"density\": 1.0}\n)\nax1.set_title(\"w at cell edges\")\n\nax2 = fig.add_subplot(122)\nmesh.plotImage(curl_w, ax=ax2)\nax2.set_title(\"curl of w at cell centers\")\n\nfig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Calculus Identities\n\nHere we show that vector calculus identities hold for the discrete\ndifferential operators. Namely that for a scalar quantity $\\phi$ and\na vector quantity $\\mathbf{v}$:\n\n\\begin{align}\\begin{align}\n    &\\nabla \\times (\\nabla \\phi ) = 0 \\\\\n    &\\nabla \\cdot (\\nabla \\times \\mathbf{v}) = 0\n    \\end{align}\\end{align}\n\n\nWe do this by computing the CURL*GRAD and DIV*CURL matricies. We then\nplot the sparse representations and show neither contain any non-zero\nentries; **e.g. each is just a matrix of zeros**.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create a mesh\nh = 5 * np.ones(20)\nmesh = TensorMesh([h, h, h], \"CCC\")\n\n# Get operators\nGRAD = mesh.nodalGrad  # nodes to edges\nDIV = mesh.faceDiv  # faces to centers\nCURL = mesh.edgeCurl  # edges to faces\n\n# Plot\nfig = plt.figure(figsize=(11, 7))\n\nax1 = fig.add_axes([0.12, 0.1, 0.2, 0.8])\nax1.spy(CURL * GRAD, markersize=0.5)\nax1.set_title(\"CURL*GRAD\")\n\nax2 = fig.add_axes([0.35, 0.64, 0.6, 0.25])\nax2.spy(DIV * CURL, markersize=0.5)\nax2.set_title(\"DIV*CURL\", pad=20)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}